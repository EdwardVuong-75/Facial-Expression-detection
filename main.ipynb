{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-17T13:28:28.866926Z",
     "start_time": "2025-09-17T13:28:28.310887Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import cv2"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Image",
   "id": "44ed3a757ea71814"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T13:16:06.071841Z",
     "start_time": "2025-09-17T13:15:59.208785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "face_cas = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "img = cv2.imread('ff.jpg')\n",
    "resize_img = cv2.resize(img,(640,480))\n",
    "gray_img = cv2.cvtColor(resize_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cas.detectMultiScale(gray_img, 1.029, 5)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(resize_img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('img', resize_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "ec5821c3d3725153",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Video",
   "id": "9f2f0caabbd5da93"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T13:10:12.611297Z",
     "start_time": "2025-09-16T13:09:15.527772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "face_cas = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    resized_frame = cv2.resize(frame, (1200, 800))\n",
    "    gray_img = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cas.detectMultiScale(gray_img, scaleFactor= 1.1, minNeighbors= 5, minSize= (300, 300))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(resized_frame, (x, y), (x + w, y + h), (0, 255, 255), 10)\n",
    "\n",
    "    cv2.imshow('video', resized_frame)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "c8a80e21fc59689b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " # Data Preparation",
   "id": "b47de92c3747b083"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T13:30:48.741063Z",
     "start_time": "2025-09-17T13:28:37.189420Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu126",
   "id": "f89d5847760698ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu126/torch-2.8.0%2Bcu126-cp311-cp311-win_amd64.whl.metadata (29 kB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu126/torchvision-0.23.0%2Bcu126-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\vuong\\pycharmprojects\\facial_expression_detection\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vuong\\pycharmprojects\\facial_expression_detection\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\vuong\\pycharmprojects\\facial_expression_detection\\.venv\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Using cached https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vuong\\pycharmprojects\\facial_expression_detection\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached https://download.pytorch.org/whl/cu126/torch-2.8.0%2Bcu126-cp311-cp311-win_amd64.whl (2915.5 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu126/torchvision-0.23.0%2Bcu126-cp311-cp311-win_amd64.whl (6.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "Using cached https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Using cached https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Using cached https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: mpmath, sympy, pillow, networkx, fsspec, filelock, torch, torchvision\n",
      "\n",
      "   ---------------------------------------- 0/8 [mpmath]\n",
      "   ---------------------------------------- 0/8 [mpmath]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ---------- ----------------------------- 2/8 [pillow]\n",
      "   ---------- ----------------------------- 2/8 [pillow]\n",
      "   --------------- ------------------------ 3/8 [networkx]\n",
      "   --------------- ------------------------ 3/8 [networkx]\n",
      "   --------------- ------------------------ 3/8 [networkx]\n",
      "   --------------- ------------------------ 3/8 [networkx]\n",
      "   --------------- ------------------------ 3/8 [networkx]\n",
      "   --------------- ------------------------ 3/8 [networkx]\n",
      "   --------------- ------------------------ 3/8 [networkx]\n",
      "   --------------- ------------------------ 3/8 [networkx]\n",
      "   --------------- ------------------------ 3/8 [networkx]\n",
      "   --------------- ------------------------ 3/8 [networkx]\n",
      "   --------------- ------------------------ 3/8 [networkx]\n",
      "   -------------------- ------------------- 4/8 [fsspec]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ------------------------------ --------- 6/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torchvision]\n",
      "   ----------------------------------- ---- 7/8 [torchvision]\n",
      "   ----------------------------------- ---- 7/8 [torchvision]\n",
      "   ----------------------------------- ---- 7/8 [torchvision]\n",
      "   ----------------------------------- ---- 7/8 [torchvision]\n",
      "   ---------------------------------------- 8/8 [torchvision]\n",
      "\n",
      "Successfully installed filelock-3.13.1 fsspec-2024.6.1 mpmath-1.3.0 networkx-3.3 pillow-11.0.0 sympy-1.13.3 torch-2.8.0+cu126 torchvision-0.23.0+cu126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T13:31:55.360925Z",
     "start_time": "2025-09-17T13:30:51.507916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets"
   ],
   "id": "f0f9b81f06672ed3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T13:31:59.070031Z",
     "start_time": "2025-09-17T13:31:59.055619Z"
    }
   },
   "cell_type": "code",
   "source": "torch.__version__",
   "id": "be54b0d4349f2dec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0+cu126'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T11:48:36.725255Z",
     "start_time": "2025-09-17T11:48:34.309376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Data_dir = \"FER_2013\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 40\n",
    "LR = 1e-3\n",
    "MODEL_OUT = \"emotion_model.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CLASS_MAP = ['angry','disgust','fear','happy','sad','surprise','neutral']\n",
    "NUM_CLASSES = len(CLASS_MAP)\n",
    "\n",
    "# --- Transforms ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),   # ensure single channel\n",
    "    transforms.Resize((48,48)),\n",
    "    transforms.ToTensor(),    # scales to [0,1]\n",
    "])\n",
    "\n",
    "# --- Dataset ---\n",
    "train_ds = datasets.ImageFolder(root=f\"{Data_dir}/train\", transform=transform)\n",
    "val_ds   = datasets.ImageFolder(root=f\"{Data_dir}/test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# --- Model ---\n",
    "class EmotionCNN(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # compute flattened size automatically\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 1, 48, 48)  # 1 grayscale image\n",
    "            dummy_out = self._forward_conv(dummy)\n",
    "            flat_size = dummy_out.view(1, -1).size(1)\n",
    "\n",
    "        self.fc1 = nn.Linear(flat_size, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def _forward_conv(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# --- Train ---\n",
    "def train_model():\n",
    "    model = EmotionCNN().to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(X)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            _, pred = out.max(1)\n",
    "            correct += pred.eq(y).sum().item()\n",
    "            total += y.size(0)\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in val_loader:\n",
    "                X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "                out = model(X)\n",
    "                _, pred = out.max(1)\n",
    "                correct += pred.eq(y).sum().item()\n",
    "                total += y.size(0)\n",
    "        val_acc = correct / total\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} - Loss {total_loss/len(train_loader):.4f} - Train acc {train_acc:.3f} - Val acc {val_acc:.3f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), MODEL_OUT)\n",
    "    print(\"Model saved:\", MODEL_OUT)\n"
   ],
   "id": "4b260c2720af4514",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_model()"
   ],
   "id": "b1b7758d899229e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Model",
   "id": "883def37463a05f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T09:32:03.206853Z",
     "start_time": "2025-09-17T09:31:21.678922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# Make sure IMG_SIZE matches training\n",
    "IMG_SIZE = 48\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Path to model and class map\n",
    "MODEL_OUT = \"emotion_model.pth\"\n",
    "CLASS_MAP = ['angry','disgust','fear','happy','sad','surprise','neutral']\n",
    "\n",
    "# Load face cascade properly\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def preprocess_face(face_gray):\n",
    "    face = cv2.resize(face_gray, (IMG_SIZE, IMG_SIZE))\n",
    "    face = face.astype(np.float32) / 255.0\n",
    "    face = np.expand_dims(face, axis=0)  # channel\n",
    "    face = np.expand_dims(face, axis=0)  # batch\n",
    "    return torch.tensor(face, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "def main(video_source=0):\n",
    "    # Load model\n",
    "    model = EmotionCNN()\n",
    "    model.load_state_dict(torch.load(MODEL_OUT, map_location=DEVICE))\n",
    "    model.to(DEVICE).eval()\n",
    "\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_gray = gray[y:y+h, x:x+w]\n",
    "            inp = preprocess_face(face_gray)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                out = model(inp)\n",
    "                probs = F.softmax(out, dim=1).cpu().numpy()[0]\n",
    "                class_id = int(np.argmax(probs))\n",
    "                label = CLASS_MAP[class_id]\n",
    "                prob = probs[class_id]\n",
    "\n",
    "            text = f\"{label} {prob:.2f}\"\n",
    "            cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "            cv2.putText(frame, text, (x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "\n",
    "        cv2.imshow(\"PyTorch Emotion Detection\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(0)\n"
   ],
   "id": "c01010621ebc5eb7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Adding a layer",
   "id": "38bf480b41d38304"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T13:32:23.740618Z",
     "start_time": "2025-09-17T13:32:22.240192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Data_dir = \"FER_2013\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 300\n",
    "LR = 1e-3\n",
    "MODEL_OUT = \"emotion_model2.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CLASS_MAP = ['angry','disgust','fear','happy','sad','surprise','neutral']\n",
    "NUM_CLASSES = len(CLASS_MAP)\n",
    "\n",
    "# --- Transforms ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),   # ensure single channel\n",
    "    transforms.Resize((48,48)),\n",
    "    transforms.ToTensor(),    # scales to [0,1]\n",
    "])\n",
    "\n",
    "# --- Dataset ---\n",
    "train_ds = datasets.ImageFolder(root=f\"{Data_dir}/train\", transform=transform)\n",
    "val_ds   = datasets.ImageFolder(root=f\"{Data_dir}/test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# --- Model ---\n",
    "class EmotionCNN(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.dropout_conv = nn.Dropout2d(0.25)\n",
    "        self.dropout_fc = nn.Dropout(0.5)\n",
    "\n",
    "        # compute flattened size automatically\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 1, 48, 48)  # 1 grayscale image\n",
    "            dummy_out = self._forward_conv(dummy)\n",
    "            flat_size = dummy_out.view(1, -1).size(1)\n",
    "\n",
    "        self.fc1 = nn.Linear(flat_size, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def _forward_conv(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.dropout_conv(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = self.dropout_conv(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout_fc(F.relu(self.fc1(x)))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# --- Train ---\n",
    "def train_model():\n",
    "    model = EmotionCNN().to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(X)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            _, pred = out.max(1)\n",
    "            correct += pred.eq(y).sum().item()\n",
    "            total += y.size(0)\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in val_loader:\n",
    "                X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "                out = model(X)\n",
    "                _, pred = out.max(1)\n",
    "                correct += pred.eq(y).sum().item()\n",
    "                total += y.size(0)\n",
    "        val_acc = correct / total\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} - Loss {total_loss/len(train_loader):.4f} - Train acc {train_acc:.3f} - Val acc {val_acc:.3f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), MODEL_OUT)\n",
    "    print(\"Model saved:\", MODEL_OUT)\n"
   ],
   "id": "6e22a191fb02a168",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T08:13:59.406138Z",
     "start_time": "2025-09-17T05:56:30.364504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model()"
   ],
   "id": "9728f9dea549f221",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300 - Loss 2.0463 - Train acc 0.225 - Val acc 0.225\n",
      "Epoch 2/300 - Loss 1.7933 - Train acc 0.254 - Val acc 0.275\n",
      "Epoch 3/300 - Loss 1.7390 - Train acc 0.277 - Val acc 0.342\n",
      "Epoch 4/300 - Loss 1.6908 - Train acc 0.298 - Val acc 0.387\n",
      "Epoch 5/300 - Loss 1.6592 - Train acc 0.312 - Val acc 0.395\n",
      "Epoch 6/300 - Loss 1.6425 - Train acc 0.318 - Val acc 0.402\n",
      "Epoch 7/300 - Loss 1.6171 - Train acc 0.333 - Val acc 0.419\n",
      "Epoch 8/300 - Loss 1.6151 - Train acc 0.333 - Val acc 0.432\n",
      "Epoch 9/300 - Loss 1.6027 - Train acc 0.337 - Val acc 0.425\n",
      "Epoch 10/300 - Loss 1.5967 - Train acc 0.340 - Val acc 0.433\n",
      "Epoch 11/300 - Loss 1.5812 - Train acc 0.347 - Val acc 0.430\n",
      "Epoch 12/300 - Loss 1.5808 - Train acc 0.347 - Val acc 0.422\n",
      "Epoch 13/300 - Loss 1.5709 - Train acc 0.351 - Val acc 0.417\n",
      "Epoch 14/300 - Loss 1.5562 - Train acc 0.357 - Val acc 0.432\n",
      "Epoch 15/300 - Loss 1.5556 - Train acc 0.351 - Val acc 0.425\n",
      "Epoch 16/300 - Loss 1.5437 - Train acc 0.359 - Val acc 0.446\n",
      "Epoch 17/300 - Loss 1.5434 - Train acc 0.357 - Val acc 0.426\n",
      "Epoch 18/300 - Loss 1.5407 - Train acc 0.359 - Val acc 0.415\n",
      "Epoch 19/300 - Loss 1.5242 - Train acc 0.365 - Val acc 0.452\n",
      "Epoch 20/300 - Loss 1.5212 - Train acc 0.368 - Val acc 0.449\n",
      "Epoch 21/300 - Loss 1.5144 - Train acc 0.369 - Val acc 0.458\n",
      "Epoch 22/300 - Loss 1.5122 - Train acc 0.370 - Val acc 0.446\n",
      "Epoch 23/300 - Loss 1.5069 - Train acc 0.372 - Val acc 0.450\n",
      "Epoch 24/300 - Loss 1.5007 - Train acc 0.374 - Val acc 0.451\n",
      "Epoch 25/300 - Loss 1.4941 - Train acc 0.375 - Val acc 0.457\n",
      "Epoch 26/300 - Loss 1.4847 - Train acc 0.379 - Val acc 0.439\n",
      "Epoch 27/300 - Loss 1.4781 - Train acc 0.382 - Val acc 0.446\n",
      "Epoch 28/300 - Loss 1.4744 - Train acc 0.381 - Val acc 0.436\n",
      "Epoch 29/300 - Loss 1.4737 - Train acc 0.382 - Val acc 0.462\n",
      "Epoch 30/300 - Loss 1.4609 - Train acc 0.385 - Val acc 0.449\n",
      "Epoch 31/300 - Loss 1.4632 - Train acc 0.385 - Val acc 0.444\n",
      "Epoch 32/300 - Loss 1.4565 - Train acc 0.389 - Val acc 0.451\n",
      "Epoch 33/300 - Loss 1.4504 - Train acc 0.392 - Val acc 0.455\n",
      "Epoch 34/300 - Loss 1.4456 - Train acc 0.393 - Val acc 0.446\n",
      "Epoch 35/300 - Loss 1.4475 - Train acc 0.390 - Val acc 0.458\n",
      "Epoch 36/300 - Loss 1.4439 - Train acc 0.392 - Val acc 0.444\n",
      "Epoch 37/300 - Loss 1.4448 - Train acc 0.392 - Val acc 0.453\n",
      "Epoch 38/300 - Loss 1.4418 - Train acc 0.391 - Val acc 0.456\n",
      "Epoch 39/300 - Loss 1.4348 - Train acc 0.394 - Val acc 0.454\n",
      "Epoch 40/300 - Loss 1.4319 - Train acc 0.394 - Val acc 0.464\n",
      "Epoch 41/300 - Loss 1.4261 - Train acc 0.398 - Val acc 0.453\n",
      "Epoch 42/300 - Loss 1.4267 - Train acc 0.395 - Val acc 0.445\n",
      "Epoch 43/300 - Loss 1.4198 - Train acc 0.399 - Val acc 0.461\n",
      "Epoch 44/300 - Loss 1.4161 - Train acc 0.401 - Val acc 0.454\n",
      "Epoch 45/300 - Loss 1.4205 - Train acc 0.397 - Val acc 0.448\n",
      "Epoch 46/300 - Loss 1.4173 - Train acc 0.398 - Val acc 0.455\n",
      "Epoch 47/300 - Loss 1.4154 - Train acc 0.399 - Val acc 0.450\n",
      "Epoch 48/300 - Loss 1.4118 - Train acc 0.401 - Val acc 0.457\n",
      "Epoch 49/300 - Loss 1.4108 - Train acc 0.399 - Val acc 0.452\n",
      "Epoch 50/300 - Loss 1.4036 - Train acc 0.401 - Val acc 0.443\n",
      "Epoch 51/300 - Loss 1.4014 - Train acc 0.404 - Val acc 0.455\n",
      "Epoch 52/300 - Loss 1.3995 - Train acc 0.405 - Val acc 0.463\n",
      "Epoch 53/300 - Loss 1.4038 - Train acc 0.403 - Val acc 0.456\n",
      "Epoch 54/300 - Loss 1.4003 - Train acc 0.401 - Val acc 0.446\n",
      "Epoch 55/300 - Loss 1.4113 - Train acc 0.398 - Val acc 0.452\n",
      "Epoch 56/300 - Loss 1.3967 - Train acc 0.405 - Val acc 0.459\n",
      "Epoch 57/300 - Loss 1.4005 - Train acc 0.400 - Val acc 0.443\n",
      "Epoch 58/300 - Loss 1.3943 - Train acc 0.404 - Val acc 0.444\n",
      "Epoch 59/300 - Loss 1.3949 - Train acc 0.403 - Val acc 0.449\n",
      "Epoch 60/300 - Loss 1.3959 - Train acc 0.405 - Val acc 0.459\n",
      "Epoch 61/300 - Loss 1.4005 - Train acc 0.402 - Val acc 0.438\n",
      "Epoch 62/300 - Loss 1.3958 - Train acc 0.404 - Val acc 0.435\n",
      "Epoch 63/300 - Loss 1.3910 - Train acc 0.407 - Val acc 0.449\n",
      "Epoch 64/300 - Loss 1.3957 - Train acc 0.403 - Val acc 0.447\n",
      "Epoch 65/300 - Loss 1.3885 - Train acc 0.406 - Val acc 0.447\n",
      "Epoch 66/300 - Loss 1.3864 - Train acc 0.406 - Val acc 0.447\n",
      "Epoch 67/300 - Loss 1.3788 - Train acc 0.409 - Val acc 0.453\n",
      "Epoch 68/300 - Loss 1.3915 - Train acc 0.404 - Val acc 0.448\n",
      "Epoch 69/300 - Loss 1.3890 - Train acc 0.408 - Val acc 0.441\n",
      "Epoch 70/300 - Loss 1.3832 - Train acc 0.411 - Val acc 0.446\n",
      "Epoch 71/300 - Loss 1.3838 - Train acc 0.409 - Val acc 0.456\n",
      "Epoch 72/300 - Loss 1.3820 - Train acc 0.409 - Val acc 0.438\n",
      "Epoch 73/300 - Loss 1.3843 - Train acc 0.405 - Val acc 0.429\n",
      "Epoch 74/300 - Loss 1.3749 - Train acc 0.411 - Val acc 0.452\n",
      "Epoch 75/300 - Loss 1.3807 - Train acc 0.410 - Val acc 0.444\n",
      "Epoch 76/300 - Loss 1.3845 - Train acc 0.407 - Val acc 0.451\n",
      "Epoch 77/300 - Loss 1.3844 - Train acc 0.408 - Val acc 0.452\n",
      "Epoch 78/300 - Loss 1.3799 - Train acc 0.412 - Val acc 0.455\n",
      "Epoch 79/300 - Loss 1.3788 - Train acc 0.411 - Val acc 0.447\n",
      "Epoch 80/300 - Loss 1.3812 - Train acc 0.411 - Val acc 0.447\n",
      "Epoch 81/300 - Loss 1.3771 - Train acc 0.412 - Val acc 0.444\n",
      "Epoch 82/300 - Loss 1.3710 - Train acc 0.411 - Val acc 0.460\n",
      "Epoch 83/300 - Loss 1.3676 - Train acc 0.419 - Val acc 0.460\n",
      "Epoch 84/300 - Loss 1.3681 - Train acc 0.418 - Val acc 0.468\n",
      "Epoch 85/300 - Loss 1.3595 - Train acc 0.425 - Val acc 0.470\n",
      "Epoch 86/300 - Loss 1.3092 - Train acc 0.455 - Val acc 0.500\n",
      "Epoch 87/300 - Loss 1.2572 - Train acc 0.482 - Val acc 0.500\n",
      "Epoch 88/300 - Loss 1.2336 - Train acc 0.497 - Val acc 0.509\n",
      "Epoch 89/300 - Loss 1.2282 - Train acc 0.499 - Val acc 0.504\n",
      "Epoch 90/300 - Loss 1.2161 - Train acc 0.502 - Val acc 0.516\n",
      "Epoch 91/300 - Loss 1.1995 - Train acc 0.512 - Val acc 0.512\n",
      "Epoch 92/300 - Loss 1.1875 - Train acc 0.517 - Val acc 0.504\n",
      "Epoch 93/300 - Loss 1.1792 - Train acc 0.520 - Val acc 0.509\n",
      "Epoch 94/300 - Loss 1.1755 - Train acc 0.523 - Val acc 0.512\n",
      "Epoch 95/300 - Loss 1.1752 - Train acc 0.524 - Val acc 0.522\n",
      "Epoch 96/300 - Loss 1.1705 - Train acc 0.529 - Val acc 0.518\n",
      "Epoch 97/300 - Loss 1.1543 - Train acc 0.533 - Val acc 0.528\n",
      "Epoch 98/300 - Loss 1.1429 - Train acc 0.536 - Val acc 0.524\n",
      "Epoch 99/300 - Loss 1.1409 - Train acc 0.539 - Val acc 0.525\n",
      "Epoch 100/300 - Loss 1.1317 - Train acc 0.541 - Val acc 0.520\n",
      "Epoch 101/300 - Loss 1.1289 - Train acc 0.544 - Val acc 0.527\n",
      "Epoch 102/300 - Loss 1.1297 - Train acc 0.541 - Val acc 0.519\n",
      "Epoch 103/300 - Loss 1.1325 - Train acc 0.542 - Val acc 0.528\n",
      "Epoch 104/300 - Loss 1.1242 - Train acc 0.547 - Val acc 0.515\n",
      "Epoch 105/300 - Loss 1.1112 - Train acc 0.553 - Val acc 0.529\n",
      "Epoch 106/300 - Loss 1.1168 - Train acc 0.551 - Val acc 0.523\n",
      "Epoch 107/300 - Loss 1.1102 - Train acc 0.553 - Val acc 0.526\n",
      "Epoch 108/300 - Loss 1.1092 - Train acc 0.554 - Val acc 0.525\n",
      "Epoch 109/300 - Loss 1.1118 - Train acc 0.551 - Val acc 0.523\n",
      "Epoch 110/300 - Loss 1.1087 - Train acc 0.554 - Val acc 0.517\n",
      "Epoch 111/300 - Loss 1.0955 - Train acc 0.561 - Val acc 0.524\n",
      "Epoch 112/300 - Loss 1.1031 - Train acc 0.557 - Val acc 0.525\n",
      "Epoch 113/300 - Loss 1.0992 - Train acc 0.559 - Val acc 0.527\n",
      "Epoch 114/300 - Loss 1.0976 - Train acc 0.559 - Val acc 0.519\n",
      "Epoch 115/300 - Loss 1.0947 - Train acc 0.561 - Val acc 0.523\n",
      "Epoch 116/300 - Loss 1.0885 - Train acc 0.561 - Val acc 0.529\n",
      "Epoch 117/300 - Loss 1.0879 - Train acc 0.563 - Val acc 0.525\n",
      "Epoch 118/300 - Loss 1.0745 - Train acc 0.567 - Val acc 0.517\n",
      "Epoch 119/300 - Loss 1.0660 - Train acc 0.566 - Val acc 0.527\n",
      "Epoch 120/300 - Loss 1.0586 - Train acc 0.567 - Val acc 0.527\n",
      "Epoch 121/300 - Loss 1.0476 - Train acc 0.571 - Val acc 0.531\n",
      "Epoch 122/300 - Loss 1.0301 - Train acc 0.574 - Val acc 0.531\n",
      "Epoch 123/300 - Loss 1.0109 - Train acc 0.582 - Val acc 0.539\n",
      "Epoch 124/300 - Loss 0.9965 - Train acc 0.587 - Val acc 0.540\n",
      "Epoch 125/300 - Loss 0.9885 - Train acc 0.593 - Val acc 0.549\n",
      "Epoch 126/300 - Loss 0.9767 - Train acc 0.599 - Val acc 0.555\n",
      "Epoch 127/300 - Loss 0.9593 - Train acc 0.605 - Val acc 0.561\n",
      "Epoch 128/300 - Loss 0.9508 - Train acc 0.609 - Val acc 0.552\n",
      "Epoch 129/300 - Loss 0.9281 - Train acc 0.620 - Val acc 0.568\n",
      "Epoch 130/300 - Loss 0.9075 - Train acc 0.633 - Val acc 0.571\n",
      "Epoch 131/300 - Loss 0.8883 - Train acc 0.642 - Val acc 0.575\n",
      "Epoch 132/300 - Loss 0.8665 - Train acc 0.654 - Val acc 0.576\n",
      "Epoch 133/300 - Loss 0.8295 - Train acc 0.669 - Val acc 0.580\n",
      "Epoch 134/300 - Loss 0.8111 - Train acc 0.679 - Val acc 0.578\n",
      "Epoch 135/300 - Loss 0.7968 - Train acc 0.684 - Val acc 0.579\n",
      "Epoch 136/300 - Loss 0.7852 - Train acc 0.693 - Val acc 0.583\n",
      "Epoch 137/300 - Loss 0.7659 - Train acc 0.697 - Val acc 0.581\n",
      "Epoch 138/300 - Loss 0.7592 - Train acc 0.699 - Val acc 0.581\n",
      "Epoch 139/300 - Loss 0.7395 - Train acc 0.708 - Val acc 0.582\n",
      "Epoch 140/300 - Loss 0.7267 - Train acc 0.711 - Val acc 0.579\n",
      "Epoch 141/300 - Loss 0.7117 - Train acc 0.720 - Val acc 0.578\n",
      "Epoch 142/300 - Loss 0.7155 - Train acc 0.717 - Val acc 0.583\n",
      "Epoch 143/300 - Loss 0.6959 - Train acc 0.727 - Val acc 0.584\n",
      "Epoch 144/300 - Loss 0.6862 - Train acc 0.732 - Val acc 0.585\n",
      "Epoch 145/300 - Loss 0.6856 - Train acc 0.732 - Val acc 0.580\n",
      "Epoch 146/300 - Loss 0.6758 - Train acc 0.736 - Val acc 0.587\n",
      "Epoch 147/300 - Loss 0.6715 - Train acc 0.741 - Val acc 0.589\n",
      "Epoch 148/300 - Loss 0.6606 - Train acc 0.743 - Val acc 0.589\n",
      "Epoch 149/300 - Loss 0.6518 - Train acc 0.744 - Val acc 0.584\n",
      "Epoch 150/300 - Loss 0.6417 - Train acc 0.751 - Val acc 0.587\n",
      "Epoch 151/300 - Loss 0.6449 - Train acc 0.751 - Val acc 0.587\n",
      "Epoch 152/300 - Loss 0.6366 - Train acc 0.756 - Val acc 0.589\n",
      "Epoch 153/300 - Loss 0.6282 - Train acc 0.756 - Val acc 0.577\n",
      "Epoch 154/300 - Loss 0.6221 - Train acc 0.762 - Val acc 0.587\n",
      "Epoch 155/300 - Loss 0.6174 - Train acc 0.762 - Val acc 0.591\n",
      "Epoch 156/300 - Loss 0.6141 - Train acc 0.763 - Val acc 0.586\n",
      "Epoch 157/300 - Loss 0.6160 - Train acc 0.764 - Val acc 0.585\n",
      "Epoch 158/300 - Loss 0.6094 - Train acc 0.767 - Val acc 0.580\n",
      "Epoch 159/300 - Loss 0.5961 - Train acc 0.775 - Val acc 0.596\n",
      "Epoch 160/300 - Loss 0.5966 - Train acc 0.771 - Val acc 0.589\n",
      "Epoch 161/300 - Loss 0.5884 - Train acc 0.777 - Val acc 0.585\n",
      "Epoch 162/300 - Loss 0.5925 - Train acc 0.775 - Val acc 0.588\n",
      "Epoch 163/300 - Loss 0.5751 - Train acc 0.782 - Val acc 0.590\n",
      "Epoch 164/300 - Loss 0.5759 - Train acc 0.781 - Val acc 0.582\n",
      "Epoch 165/300 - Loss 0.5694 - Train acc 0.786 - Val acc 0.586\n",
      "Epoch 166/300 - Loss 0.5682 - Train acc 0.786 - Val acc 0.579\n",
      "Epoch 167/300 - Loss 0.5645 - Train acc 0.788 - Val acc 0.588\n",
      "Epoch 168/300 - Loss 0.5562 - Train acc 0.793 - Val acc 0.582\n",
      "Epoch 169/300 - Loss 0.5536 - Train acc 0.789 - Val acc 0.582\n",
      "Epoch 170/300 - Loss 0.5512 - Train acc 0.792 - Val acc 0.581\n",
      "Epoch 171/300 - Loss 0.5487 - Train acc 0.794 - Val acc 0.591\n",
      "Epoch 172/300 - Loss 0.5424 - Train acc 0.796 - Val acc 0.589\n",
      "Epoch 173/300 - Loss 0.5404 - Train acc 0.798 - Val acc 0.582\n",
      "Epoch 174/300 - Loss 0.5355 - Train acc 0.803 - Val acc 0.583\n",
      "Epoch 175/300 - Loss 0.5252 - Train acc 0.804 - Val acc 0.584\n",
      "Epoch 176/300 - Loss 0.5202 - Train acc 0.808 - Val acc 0.583\n",
      "Epoch 177/300 - Loss 0.5129 - Train acc 0.810 - Val acc 0.587\n",
      "Epoch 178/300 - Loss 0.5111 - Train acc 0.811 - Val acc 0.587\n",
      "Epoch 179/300 - Loss 0.4986 - Train acc 0.817 - Val acc 0.591\n",
      "Epoch 180/300 - Loss 0.4989 - Train acc 0.815 - Val acc 0.589\n",
      "Epoch 181/300 - Loss 0.4869 - Train acc 0.821 - Val acc 0.591\n",
      "Epoch 182/300 - Loss 0.4755 - Train acc 0.828 - Val acc 0.594\n",
      "Epoch 183/300 - Loss 0.4663 - Train acc 0.826 - Val acc 0.593\n",
      "Epoch 184/300 - Loss 0.4661 - Train acc 0.826 - Val acc 0.596\n",
      "Epoch 185/300 - Loss 0.4594 - Train acc 0.832 - Val acc 0.595\n",
      "Epoch 186/300 - Loss 0.4559 - Train acc 0.831 - Val acc 0.591\n",
      "Epoch 187/300 - Loss 0.4513 - Train acc 0.835 - Val acc 0.595\n",
      "Epoch 188/300 - Loss 0.4522 - Train acc 0.834 - Val acc 0.593\n",
      "Epoch 189/300 - Loss 0.4447 - Train acc 0.836 - Val acc 0.596\n",
      "Epoch 190/300 - Loss 0.4318 - Train acc 0.843 - Val acc 0.597\n",
      "Epoch 191/300 - Loss 0.4402 - Train acc 0.839 - Val acc 0.595\n",
      "Epoch 192/300 - Loss 0.4229 - Train acc 0.848 - Val acc 0.600\n",
      "Epoch 193/300 - Loss 0.4291 - Train acc 0.844 - Val acc 0.600\n",
      "Epoch 194/300 - Loss 0.4206 - Train acc 0.846 - Val acc 0.596\n",
      "Epoch 195/300 - Loss 0.4221 - Train acc 0.847 - Val acc 0.591\n",
      "Epoch 196/300 - Loss 0.4169 - Train acc 0.847 - Val acc 0.590\n",
      "Epoch 197/300 - Loss 0.4129 - Train acc 0.850 - Val acc 0.594\n",
      "Epoch 198/300 - Loss 0.4080 - Train acc 0.851 - Val acc 0.592\n",
      "Epoch 199/300 - Loss 0.4033 - Train acc 0.853 - Val acc 0.597\n",
      "Epoch 200/300 - Loss 0.4015 - Train acc 0.854 - Val acc 0.597\n",
      "Epoch 201/300 - Loss 0.4010 - Train acc 0.855 - Val acc 0.597\n",
      "Epoch 202/300 - Loss 0.3964 - Train acc 0.857 - Val acc 0.591\n",
      "Epoch 203/300 - Loss 0.3947 - Train acc 0.858 - Val acc 0.597\n",
      "Epoch 204/300 - Loss 0.3851 - Train acc 0.862 - Val acc 0.596\n",
      "Epoch 205/300 - Loss 0.3971 - Train acc 0.857 - Val acc 0.594\n",
      "Epoch 206/300 - Loss 0.3835 - Train acc 0.861 - Val acc 0.593\n",
      "Epoch 207/300 - Loss 0.3772 - Train acc 0.864 - Val acc 0.592\n",
      "Epoch 208/300 - Loss 0.3665 - Train acc 0.868 - Val acc 0.596\n",
      "Epoch 209/300 - Loss 0.3758 - Train acc 0.865 - Val acc 0.596\n",
      "Epoch 210/300 - Loss 0.3683 - Train acc 0.868 - Val acc 0.591\n",
      "Epoch 211/300 - Loss 0.3749 - Train acc 0.865 - Val acc 0.592\n",
      "Epoch 212/300 - Loss 0.3520 - Train acc 0.874 - Val acc 0.598\n",
      "Epoch 213/300 - Loss 0.3473 - Train acc 0.876 - Val acc 0.591\n",
      "Epoch 214/300 - Loss 0.3572 - Train acc 0.871 - Val acc 0.597\n",
      "Epoch 215/300 - Loss 0.3577 - Train acc 0.874 - Val acc 0.595\n",
      "Epoch 216/300 - Loss 0.3427 - Train acc 0.879 - Val acc 0.596\n",
      "Epoch 217/300 - Loss 0.3466 - Train acc 0.878 - Val acc 0.599\n",
      "Epoch 218/300 - Loss 0.3405 - Train acc 0.879 - Val acc 0.596\n",
      "Epoch 219/300 - Loss 0.3449 - Train acc 0.879 - Val acc 0.591\n",
      "Epoch 220/300 - Loss 0.3302 - Train acc 0.882 - Val acc 0.595\n",
      "Epoch 221/300 - Loss 0.3349 - Train acc 0.882 - Val acc 0.593\n",
      "Epoch 222/300 - Loss 0.3254 - Train acc 0.887 - Val acc 0.595\n",
      "Epoch 223/300 - Loss 0.3279 - Train acc 0.883 - Val acc 0.591\n",
      "Epoch 224/300 - Loss 0.3198 - Train acc 0.889 - Val acc 0.591\n",
      "Epoch 225/300 - Loss 0.3207 - Train acc 0.888 - Val acc 0.597\n",
      "Epoch 226/300 - Loss 0.3275 - Train acc 0.886 - Val acc 0.594\n",
      "Epoch 227/300 - Loss 0.3209 - Train acc 0.889 - Val acc 0.594\n",
      "Epoch 228/300 - Loss 0.3208 - Train acc 0.888 - Val acc 0.598\n",
      "Epoch 229/300 - Loss 0.3116 - Train acc 0.891 - Val acc 0.600\n",
      "Epoch 230/300 - Loss 0.3162 - Train acc 0.891 - Val acc 0.592\n",
      "Epoch 231/300 - Loss 0.3049 - Train acc 0.895 - Val acc 0.597\n",
      "Epoch 232/300 - Loss 0.3008 - Train acc 0.895 - Val acc 0.597\n",
      "Epoch 233/300 - Loss 0.2966 - Train acc 0.899 - Val acc 0.593\n",
      "Epoch 234/300 - Loss 0.3123 - Train acc 0.893 - Val acc 0.597\n",
      "Epoch 235/300 - Loss 0.3071 - Train acc 0.894 - Val acc 0.591\n",
      "Epoch 236/300 - Loss 0.3005 - Train acc 0.895 - Val acc 0.593\n",
      "Epoch 237/300 - Loss 0.2889 - Train acc 0.900 - Val acc 0.593\n",
      "Epoch 238/300 - Loss 0.2884 - Train acc 0.901 - Val acc 0.594\n",
      "Epoch 239/300 - Loss 0.2926 - Train acc 0.898 - Val acc 0.591\n",
      "Epoch 240/300 - Loss 0.2960 - Train acc 0.898 - Val acc 0.588\n",
      "Epoch 241/300 - Loss 0.2721 - Train acc 0.906 - Val acc 0.592\n",
      "Epoch 242/300 - Loss 0.2802 - Train acc 0.903 - Val acc 0.595\n",
      "Epoch 243/300 - Loss 0.2744 - Train acc 0.906 - Val acc 0.594\n",
      "Epoch 244/300 - Loss 0.2799 - Train acc 0.904 - Val acc 0.593\n",
      "Epoch 245/300 - Loss 0.2814 - Train acc 0.902 - Val acc 0.597\n",
      "Epoch 246/300 - Loss 0.2696 - Train acc 0.907 - Val acc 0.599\n",
      "Epoch 247/300 - Loss 0.2819 - Train acc 0.903 - Val acc 0.597\n",
      "Epoch 248/300 - Loss 0.2680 - Train acc 0.907 - Val acc 0.601\n",
      "Epoch 249/300 - Loss 0.2746 - Train acc 0.908 - Val acc 0.594\n",
      "Epoch 250/300 - Loss 0.2673 - Train acc 0.909 - Val acc 0.598\n",
      "Epoch 251/300 - Loss 0.2667 - Train acc 0.908 - Val acc 0.595\n",
      "Epoch 252/300 - Loss 0.2573 - Train acc 0.913 - Val acc 0.590\n",
      "Epoch 253/300 - Loss 0.2581 - Train acc 0.913 - Val acc 0.590\n",
      "Epoch 254/300 - Loss 0.2598 - Train acc 0.911 - Val acc 0.592\n",
      "Epoch 255/300 - Loss 0.2570 - Train acc 0.912 - Val acc 0.594\n",
      "Epoch 256/300 - Loss 0.2581 - Train acc 0.911 - Val acc 0.587\n",
      "Epoch 257/300 - Loss 0.2501 - Train acc 0.917 - Val acc 0.590\n",
      "Epoch 258/300 - Loss 0.2515 - Train acc 0.914 - Val acc 0.592\n",
      "Epoch 259/300 - Loss 0.2564 - Train acc 0.913 - Val acc 0.593\n",
      "Epoch 260/300 - Loss 0.2478 - Train acc 0.915 - Val acc 0.593\n",
      "Epoch 261/300 - Loss 0.2488 - Train acc 0.916 - Val acc 0.600\n",
      "Epoch 262/300 - Loss 0.2390 - Train acc 0.918 - Val acc 0.591\n",
      "Epoch 263/300 - Loss 0.2452 - Train acc 0.917 - Val acc 0.596\n",
      "Epoch 264/300 - Loss 0.2390 - Train acc 0.919 - Val acc 0.592\n",
      "Epoch 265/300 - Loss 0.2414 - Train acc 0.919 - Val acc 0.594\n",
      "Epoch 266/300 - Loss 0.2382 - Train acc 0.919 - Val acc 0.588\n",
      "Epoch 267/300 - Loss 0.2382 - Train acc 0.921 - Val acc 0.593\n",
      "Epoch 268/300 - Loss 0.2361 - Train acc 0.921 - Val acc 0.595\n",
      "Epoch 269/300 - Loss 0.2413 - Train acc 0.920 - Val acc 0.598\n",
      "Epoch 270/300 - Loss 0.2307 - Train acc 0.923 - Val acc 0.594\n",
      "Epoch 271/300 - Loss 0.2296 - Train acc 0.924 - Val acc 0.591\n",
      "Epoch 272/300 - Loss 0.2273 - Train acc 0.924 - Val acc 0.585\n",
      "Epoch 273/300 - Loss 0.2263 - Train acc 0.924 - Val acc 0.590\n",
      "Epoch 274/300 - Loss 0.2269 - Train acc 0.924 - Val acc 0.592\n",
      "Epoch 275/300 - Loss 0.2252 - Train acc 0.926 - Val acc 0.591\n",
      "Epoch 276/300 - Loss 0.2254 - Train acc 0.925 - Val acc 0.593\n",
      "Epoch 277/300 - Loss 0.2213 - Train acc 0.926 - Val acc 0.595\n",
      "Epoch 278/300 - Loss 0.2217 - Train acc 0.928 - Val acc 0.595\n",
      "Epoch 279/300 - Loss 0.2229 - Train acc 0.924 - Val acc 0.594\n",
      "Epoch 280/300 - Loss 0.2248 - Train acc 0.926 - Val acc 0.592\n",
      "Epoch 281/300 - Loss 0.2224 - Train acc 0.925 - Val acc 0.598\n",
      "Epoch 282/300 - Loss 0.2211 - Train acc 0.926 - Val acc 0.594\n",
      "Epoch 283/300 - Loss 0.2150 - Train acc 0.928 - Val acc 0.595\n",
      "Epoch 284/300 - Loss 0.2146 - Train acc 0.927 - Val acc 0.592\n",
      "Epoch 285/300 - Loss 0.2115 - Train acc 0.930 - Val acc 0.591\n",
      "Epoch 286/300 - Loss 0.2082 - Train acc 0.930 - Val acc 0.590\n",
      "Epoch 287/300 - Loss 0.2204 - Train acc 0.925 - Val acc 0.593\n",
      "Epoch 288/300 - Loss 0.2023 - Train acc 0.935 - Val acc 0.597\n",
      "Epoch 289/300 - Loss 0.2187 - Train acc 0.928 - Val acc 0.597\n",
      "Epoch 290/300 - Loss 0.2092 - Train acc 0.932 - Val acc 0.595\n",
      "Epoch 291/300 - Loss 0.2133 - Train acc 0.928 - Val acc 0.591\n",
      "Epoch 292/300 - Loss 0.2057 - Train acc 0.931 - Val acc 0.594\n",
      "Epoch 293/300 - Loss 0.2122 - Train acc 0.929 - Val acc 0.593\n",
      "Epoch 294/300 - Loss 0.2099 - Train acc 0.931 - Val acc 0.589\n",
      "Epoch 295/300 - Loss 0.2066 - Train acc 0.932 - Val acc 0.592\n",
      "Epoch 296/300 - Loss 0.2000 - Train acc 0.934 - Val acc 0.594\n",
      "Epoch 297/300 - Loss 0.2064 - Train acc 0.930 - Val acc 0.587\n",
      "Epoch 298/300 - Loss 0.1964 - Train acc 0.934 - Val acc 0.583\n",
      "Epoch 299/300 - Loss 0.2055 - Train acc 0.932 - Val acc 0.588\n",
      "Epoch 300/300 - Loss 0.2038 - Train acc 0.932 - Val acc 0.588\n",
      "Model saved: emotion_model2.pth\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load model",
   "id": "2ab999e36e5a683b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T13:32:38.056651Z",
     "start_time": "2025-09-17T13:32:25.302899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# Make sure IMG_SIZE matches training\n",
    "IMG_SIZE = 48\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Path to model and class map\n",
    "MODEL_OUT = \"emotion_model2.pth\"\n",
    "CLASS_MAP = ['angry','disgust','fear','happy','sad','surprise','neutral']\n",
    "\n",
    "# Load face cascade properly\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def preprocess_face(face_gray):\n",
    "    face = cv2.resize(face_gray, (IMG_SIZE, IMG_SIZE))\n",
    "    face = face.astype(np.float32) / 255.0\n",
    "    face = np.expand_dims(face, axis=0)  # channel\n",
    "    face = np.expand_dims(face, axis=0)  # batch\n",
    "    return torch.tensor(face, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "def main(video_source=0):\n",
    "    # Load model\n",
    "    model = EmotionCNN()\n",
    "    model.load_state_dict(torch.load(MODEL_OUT, map_location=DEVICE))\n",
    "    model.to(DEVICE).eval()\n",
    "\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        #if not ret:\n",
    "            #break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_gray = gray[y:y+h, x:x+w]\n",
    "            inp = preprocess_face(face_gray)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                out = model(inp)\n",
    "                probs = F.softmax(out, dim=1).cpu().numpy()[0]\n",
    "                class_id = int(np.argmax(probs))\n",
    "                label = CLASS_MAP[class_id]\n",
    "                prob = probs[class_id]\n",
    "\n",
    "            text = f\"{label} {prob:.2f}\"\n",
    "            cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "            cv2.putText(frame, text, (x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "\n",
    "        cv2.imshow(\"PyTorch Emotion Detection\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(\"vid1.mp4\")\n"
   ],
   "id": "d55f02d401222bc",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "66541081541298af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "441dde03613f8393"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
